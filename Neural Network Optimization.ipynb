{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>1</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATUS   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0           1      5000              1                     0.0   \n",
       "1           1    108590              1                     0.0   \n",
       "2           1      5000              0                     0.0   \n",
       "3           1      6692              1                     0.0   \n",
       "4           1    142590              1                     0.0   \n",
       "...       ...       ...            ...                     ...   \n",
       "34294       1      5000              0                     0.0   \n",
       "34295       1      5000              0                     0.0   \n",
       "34296       1      5000              0                     0.0   \n",
       "34297       1      5000              1                     0.0   \n",
       "34298       1  36500179              0                     0.0   \n",
       "\n",
       "       APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                       1.0                   0.0                  0.0   \n",
       "1                       0.0                   0.0                  1.0   \n",
       "2                       0.0                   0.0                  0.0   \n",
       "3                       0.0                   0.0                  1.0   \n",
       "4                       0.0                   0.0                  1.0   \n",
       "...                     ...                   ...                  ...   \n",
       "34294                   0.0                   0.0                  0.0   \n",
       "34295                   0.0                   0.0                  0.0   \n",
       "34296                   0.0                   0.0                  1.0   \n",
       "34297                   0.0                   0.0                  0.0   \n",
       "34298                   0.0                   0.0                  1.0   \n",
       "\n",
       "       APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                      0.0                  0.0                  0.0  ...   \n",
       "1                      0.0                  0.0                  0.0  ...   \n",
       "2                      0.0                  1.0                  0.0  ...   \n",
       "3                      0.0                  0.0                  0.0  ...   \n",
       "4                      0.0                  0.0                  0.0  ...   \n",
       "...                    ...                  ...                  ...  ...   \n",
       "34294                  1.0                  0.0                  0.0  ...   \n",
       "34295                  1.0                  0.0                  0.0  ...   \n",
       "34296                  0.0                  0.0                  0.0  ...   \n",
       "34297                  0.0                  1.0                  0.0  ...   \n",
       "34298                  0.0                  0.0                  0.0  ...   \n",
       "\n",
       "       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                    0.0                     0.0                       0.0   \n",
       "1                    1.0                     0.0                       0.0   \n",
       "2                    0.0                     0.0                       0.0   \n",
       "3                    0.0                     1.0                       0.0   \n",
       "4                    0.0                     0.0                       1.0   \n",
       "...                  ...                     ...                       ...   \n",
       "34294                0.0                     0.0                       0.0   \n",
       "34295                0.0                     0.0                       0.0   \n",
       "34296                0.0                     0.0                       0.0   \n",
       "34297                0.0                     0.0                       0.0   \n",
       "34298                0.0                     0.0                       0.0   \n",
       "\n",
       "       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                     0.0               0.0                     0.0   \n",
       "1                     0.0               0.0                     0.0   \n",
       "2                     0.0               0.0                     0.0   \n",
       "3                     0.0               0.0                     0.0   \n",
       "4                     0.0               0.0                     0.0   \n",
       "...                   ...               ...                     ...   \n",
       "34294                 0.0               0.0                     0.0   \n",
       "34295                 0.0               0.0                     0.0   \n",
       "34296                 0.0               0.0                     0.0   \n",
       "34297                 0.0               0.0                     0.0   \n",
       "34298                 0.0               1.0                     0.0   \n",
       "\n",
       "       INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0                  0.0                0.0                       1.0   \n",
       "1                  0.0                0.0                       1.0   \n",
       "2                  0.0                0.0                       1.0   \n",
       "3                  0.0                0.0                       1.0   \n",
       "4                  0.0                0.0                       1.0   \n",
       "...                ...                ...                       ...   \n",
       "34294              0.0                0.0                       1.0   \n",
       "34295              0.0                0.0                       1.0   \n",
       "34296              0.0                0.0                       1.0   \n",
       "34297              0.0                0.0                       1.0   \n",
       "34298              0.0                0.0                       1.0   \n",
       "\n",
       "       SPECIAL_CONSIDERATIONS_Y  \n",
       "0                           0.0  \n",
       "1                           0.0  \n",
       "2                           0.0  \n",
       "3                           0.0  \n",
       "4                           0.0  \n",
       "...                         ...  \n",
       "34294                       0.0  \n",
       "34295                       0.0  \n",
       "34296                       0.0  \n",
       "34297                       0.0  \n",
       "34298                       0.0  \n",
       "\n",
       "[34299 rows x 44 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"MachineLearningReady.csv\",index_col=0)\n",
    "application_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "X = application_df.drop(columns=[\"IS_SUCCESSFUL\"])\n",
    "y = application_df[\"IS_SUCCESSFUL\"]\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import checkpoint dependencies\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model performance dataframe\n",
    "performance = pd.DataFrame(columns = [\"h1_nodes\",\"h2_nodes\",\"hidden_func_1\",\"hidden_func_2\",\"output_func\",\"loss\",\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 12 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.2093 - accuracy: 0.3459 - 312ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.8587 - accuracy: 0.5867 - 304ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7079 - accuracy: 0.6378 - 292ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.6249 - accuracy: 0.7088 - 299ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6878 - accuracy: 0.5228 - 308ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.2219 - accuracy: 0.5401 - 305ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6458 - accuracy: 0.6779 - 390ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6979 - accuracy: 0.5497 - 309ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.4192 - accuracy: 0.4731 - 298ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6469 - accuracy: 0.6556 - 283ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6738 - accuracy: 0.5757 - 313ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.4833 - accuracy: 0.5332 - 314ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7675 - accuracy: 0.5371 - 311ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7026 - accuracy: 0.5576 - 297ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.3107 - accuracy: 0.5177 - 286ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.8273 - accuracy: 0.3401 - 301ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6962 - accuracy: 0.5836 - 293ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7486 - accuracy: 0.5481 - 293ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.1206 - accuracy: 0.7045 - 292ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7805 - accuracy: 0.6954 - 333ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7525 - accuracy: 0.4547 - 419ms/epoch - 2ms/step\n",
      "Testing 12 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.8896 - accuracy: 0.5257 - 289ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7247 - accuracy: 0.5190 - 309ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.3349 - accuracy: 0.6921 - 276ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6566 - accuracy: 0.6350 - 334ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6656 - accuracy: 0.6414 - 310ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.9761 - accuracy: 0.4783 - 283ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.0146 - accuracy: 0.3827 - 291ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6834 - accuracy: 0.6006 - 397ms/epoch - 1ms/step\n",
      "Testing 12 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7189 - accuracy: 0.6001 - 297ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.8316 - accuracy: 0.6948 - 377ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.8089 - accuracy: 0.5767 - 301ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7576 - accuracy: 0.5691 - 301ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6693 - accuracy: 0.6934 - 299ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.9900 - accuracy: 0.7022 - 284ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6105 - accuracy: 0.7002 - 296ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7313 - accuracy: 0.7001 - 294ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7512 - accuracy: 0.5085 - 281ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7537 - accuracy: 0.5429 - 307ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.2015 - accuracy: 0.5317 - 308ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.9153 - accuracy: 0.5332 - 292ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.1731 - accuracy: 0.6443 - 303ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6361 - accuracy: 0.6819 - 339ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.4198 - accuracy: 0.4548 - 271ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.2814 - accuracy: 0.3135 - 316ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.8568 - accuracy: 0.5051 - 476ms/epoch - 2ms/step\n",
      "Testing 24 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.9415 - accuracy: 0.6978 - 302ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6877 - accuracy: 0.5292 - 304ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7534 - accuracy: 0.4490 - 297ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6763 - accuracy: 0.6940 - 306ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.9176 - accuracy: 0.6376 - 290ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7642 - accuracy: 0.5432 - 309ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6581 - accuracy: 0.6833 - 309ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.8805 - accuracy: 0.6337 - 277ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7583 - accuracy: 0.4922 - 305ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7166 - accuracy: 0.5229 - 295ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7039 - accuracy: 0.6307 - 293ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6596 - accuracy: 0.6085 - 297ms/epoch - 1ms/step\n",
      "Testing 24 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6353 - accuracy: 0.6975 - 293ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 24 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.8353 - accuracy: 0.5023 - 309ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.9757 - accuracy: 0.6987 - 382ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7603 - accuracy: 0.6957 - 340ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7388 - accuracy: 0.7026 - 359ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.0240 - accuracy: 0.6927 - 263ms/epoch - 981us/step\n",
      "Testing 36 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6594 - accuracy: 0.6316 - 432ms/epoch - 2ms/step\n",
      "Testing 36 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.1897 - accuracy: 0.6854 - 376ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6772 - accuracy: 0.5694 - 384ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7566 - accuracy: 0.4676 - 266ms/epoch - 992us/step\n",
      "Testing 36 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.4445 - accuracy: 0.6977 - 373ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 12 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6850 - accuracy: 0.6517 - 400ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6445 - accuracy: 0.6956 - 346ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 1s - loss: 0.9177 - accuracy: 0.4785 - 512ms/epoch - 2ms/step\n",
      "Testing 36 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7248 - accuracy: 0.5394 - 191ms/epoch - 712us/step\n",
      "Testing 36 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6407 - accuracy: 0.6195 - 387ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7791 - accuracy: 0.6395 - 249ms/epoch - 929us/step\n",
      "Testing 36 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.2423 - accuracy: 0.6962 - 427ms/epoch - 2ms/step\n",
      "Testing 36 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.9692 - accuracy: 0.5530 - 297ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6274 - accuracy: 0.6947 - 338ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6414 - accuracy: 0.6364 - 317ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 24 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.9580 - accuracy: 0.5829 - 416ms/epoch - 2ms/step\n",
      "Testing 36 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7400 - accuracy: 0.6645 - 315ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6866 - accuracy: 0.6348 - 286ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6823 - accuracy: 0.6562 - 288ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.8729 - accuracy: 0.6919 - 264ms/epoch - 987us/step\n",
      "Testing 36 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.7022 - accuracy: 0.6780 - 290ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.8580 - accuracy: 0.5475 - 295ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.8636 - accuracy: 0.5500 - 291ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.6415 - accuracy: 0.6462 - 280ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 1.1757 - accuracy: 0.5342 - 294ms/epoch - 1ms/step\n",
      "Testing 36 in h.1, 36 in h.2, with relu as the activation function\n",
      "268/268 - 0s - loss: 0.8873 - accuracy: 0.4790 - 365ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Test Multiple configurations\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "node_counts_1 = [12,24,36]\n",
    "node_counts_2 = [12,24,36]\n",
    "functions = [\"relu\"]\n",
    "attempts = 10\n",
    "\n",
    "# Test all combinations\n",
    "for nodes_1 in node_counts_1:\n",
    "    for nodes_2 in node_counts_2:\n",
    "        for hidden_func_1 in functions:\n",
    "            for _ in range(attempts):\n",
    "                print(f\"Testing {nodes_1} in h.1, {nodes_2} in h.2, with {hidden_func_1} as the activation function\")\n",
    "                # init the network\n",
    "                nn = tf.keras.models.Sequential()\n",
    "\n",
    "                # First hidden layer\n",
    "                nn.add(\n",
    "                    tf.keras.layers.Dense(units=nodes_1, input_dim=number_input_features, activation=hidden_func_1)\n",
    "                )\n",
    "\n",
    "                # Second hidden layer\n",
    "                nn.add(tf.keras.layers.Dense(units=nodes_2, activation=\"relu\"))\n",
    "\n",
    "                # Output layer\n",
    "                nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "                # Compile the model\n",
    "                nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "                # Train the model\n",
    "                fit_model = nn.fit(X_train,y_train,epochs=100,verbose=0)\n",
    "\n",
    "                # Evaluate the model using the test data\n",
    "                model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "\n",
    "                # Record the success of the model\n",
    "                performance = performance.append({\"h1_nodes\" : nodes_1,\n",
    "                                                  \"h2_nodes\" : nodes_2,\n",
    "                                                  \"hidden_func_1\" : hidden_func_1,\n",
    "                                                  \"hidden_func_2\" : \"relu\",\n",
    "                                                  \"output_func\" : \"sigmoid\",\n",
    "                                                  \"Loss\" : model_loss,\n",
    "                                                  \"accuracy\" :model_accuracy},ignore_index=True)\n",
    "                if model_accuracy >= max(performance[\"accuracy\"]) : \n",
    "                    nn.save(\"Top_performing.h5\")\n",
    "performance.to_csv(\"Model_Performance_100epoch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='h1_nodes'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Performance by h1 nodes\n",
    "performance.groupby(\"h1_nodes\")[\"accuracy\"].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='h2_nodes'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Performance by h2 nodes\n",
    "performance.groupby(\"h2_nodes\")[\"accuracy\"].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum accuracy was 0.7088046669960022\n",
      "The minimum loss was 0.6104637384414673\n"
     ]
    }
   ],
   "source": [
    "print(f\"The maximum accuracy was {performance['accuracy'].max()}\")\n",
    "print(f\"The minimum loss was {performance['Loss'].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden_func_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591176</td>\n",
       "      <td>0.882122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               loss  accuracy      Loss\n",
       "hidden_func_2                          \n",
       "relu            NaN  0.591176  0.882122"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.groupby(\"hidden_func_2\").mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The Performance DF wasnt setup correctly so none of the data was saved but this is the results from terminal top was .71 %\n",
    "test counts\n",
    "node_counts = [4,6,8]\n",
    "functions = [\"relu\",\"sigmoid\",\"tanh\"]\n",
    "\n",
    "\n",
    "[4, 4, 'relu', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 811us/step - loss: 3.5890 - accuracy: 0.5027\n",
    "[4, 4, 'relu', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 818us/step - loss: 0.6912 - accuracy: 0.5222\n",
    "[4, 4, 'relu', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 806us/step - loss: 5.1133 - accuracy: 0.4751\n",
    "[4, 4, 'relu', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 782us/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[4, 4, 'relu', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 843us/step - loss: 0.7234 - accuracy: 0.4668\n",
    "[4, 4, 'relu', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 850us/step - loss: 0.7736 - accuracy: 0.4278\n",
    "[4, 4, 'relu', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 826us/step - loss: 3.8637 - accuracy: 0.4412\n",
    "[4, 4, 'relu', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 823us/step - loss: 0.6798 - accuracy: 0.5650\n",
    "[4, 4, 'relu', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 833us/step - loss: 5.5592 - accuracy: 0.4594\n",
    "[4, 4, 'sigmoid', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 846us/step - loss: 0.7752 - accuracy: 0.3988\n",
    "[4, 4, 'sigmoid', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 841us/step - loss: 0.6831 - accuracy: 0.6209\n",
    "[4, 4, 'sigmoid', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 1ms/step - loss: 0.7754 - accuracy: 0.4915\n",
    "[4, 4, 'sigmoid', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 860us/step - loss: 8.2031 - accuracy: 0.4668\n",
    "[4, 4, 'sigmoid', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 805us/step - loss: 0.6871 - accuracy: 0.5339\n",
    "[4, 4, 'sigmoid', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 808us/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[4, 4, 'sigmoid', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 778us/step - loss: 4.8523 - accuracy: 0.4328\n",
    "[4, 4, 'sigmoid', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 746us/step - loss: 0.6899 - accuracy: 0.5356\n",
    "[4, 4, 'sigmoid', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 786us/step - loss: 1.9821 - accuracy: 0.4234\n",
    "[4, 4, 'tanh', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 691us/step - loss: 5.0611 - accuracy: 0.4573\n",
    "[4, 4, 'tanh', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 739us/step - loss: 0.7098 - accuracy: 0.4777\n",
    "[4, 4, 'tanh', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 776us/step - loss: 8.0384 - accuracy: 0.4666\n",
    "[4, 4, 'tanh', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 892us/step - loss: 0.7888 - accuracy: 0.4752\n",
    "[4, 4, 'tanh', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 869us/step - loss: 0.6894 - accuracy: 0.5382\n",
    "[4, 4, 'tanh', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 745us/step - loss: 5.6464 - accuracy: 0.4668\n",
    "[4, 4, 'tanh', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 764us/step - loss: 4.4850 - accuracy: 0.4668\n",
    "[4, 4, 'tanh', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 789us/step - loss: 0.7234 - accuracy: 0.5698\n",
    "[4, 4, 'tanh', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 921us/step - loss: 3.7821 - accuracy: 0.4940\n",
    "[4, 6, 'relu', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 916us/step - loss: 4.6645 - accuracy: 0.4422\n",
    "[4, 6, 'relu', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 772us/step - loss: 0.7057 - accuracy: 0.5483\n",
    "[4, 6, 'relu', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 737us/step - loss: 4.8888 - accuracy: 0.4709\n",
    "[4, 6, 'relu', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 792us/step - loss: 7.1187 - accuracy: 0.5332\n",
    "[4, 6, 'relu', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 802us/step - loss: 0.7557 - accuracy: 0.5327\n",
    "[4, 6, 'relu', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 811us/step - loss: 8.2227 - accuracy: 0.4668\n",
    "[4, 6, 'relu', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 885us/step - loss: 3.3463 - accuracy: 0.5762\n",
    "[4, 6, 'relu', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 822us/step - loss: 0.6781 - accuracy: 0.6146\n",
    "[4, 6, 'relu', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 856us/step - loss: 3.2002 - accuracy: 0.5548\n",
    "[4, 6, 'sigmoid', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 815us/step - loss: 2.1149 - accuracy: 0.4515\n",
    "[4, 6, 'sigmoid', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 799us/step - loss: 0.6924 - accuracy: 0.5310\n",
    "[4, 6, 'sigmoid', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 786us/step - loss: 0.7659 - accuracy: 0.5299\n",
    "[4, 6, 'sigmoid', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 811us/step - loss: 0.7071 - accuracy: 0.4869\n",
    "[4, 6, 'sigmoid', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 799us/step - loss: 0.6925 - accuracy: 0.5332\n",
    "[4, 6, 'sigmoid', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 781us/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[4, 6, 'sigmoid', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 817us/step - loss: 6.8431 - accuracy: 0.4668\n",
    "[4, 6, 'sigmoid', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 1s 775us/step - loss: 0.7092 - accuracy: 0.4693\n",
    "[4, 6, 'sigmoid', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 860us/step - loss: 0.7083 - accuracy: 0.5900\n",
    "[4, 6, 'tanh', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 814us/step - loss: 3.5246 - accuracy: 0.4462\n",
    "[4, 6, 'tanh', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 793us/step - loss: 0.7958 - accuracy: 0.5339\n",
    "[4, 6, 'tanh', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 823us/step - loss: 8.2232 - accuracy: 0.4668\n",
    "[4, 6, 'tanh', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 722us/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[4, 6, 'tanh', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 769us/step - loss: 0.7059 - accuracy: 0.4777\n",
    "[4, 6, 'tanh', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 731us/step - loss: 0.8779 - accuracy: 0.5310\n",
    "[4, 6, 'tanh', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 740us/step - loss: 6.2426 - accuracy: 0.4405\n",
    "[4, 6, 'tanh', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 744us/step - loss: 0.7047 - accuracy: 0.5177\n",
    "[4, 6, 'tanh', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 698us/step - loss: 3.3812 - accuracy: 0.4659\n",
    "[4, 8, 'relu', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 722us/step - loss: 2.4278 - accuracy: 0.4814\n",
    "[4, 8, 'relu', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 743us/step - loss: 0.7437 - accuracy: 0.5545\n",
    "[4, 8, 'relu', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 716us/step - loss: 7.0817 - accuracy: 0.4734\n",
    "[4, 8, 'relu', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 706us/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[4, 8, 'relu', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 729us/step - loss: 0.7079 - accuracy: 0.5332\n",
    "[4, 8, 'relu', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 728us/step - loss: 7.3991 - accuracy: 0.4672\n",
    "[4, 8, 'relu', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 750us/step - loss: 4.6018 - accuracy: 0.4576\n",
    "[4, 8, 'relu', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 718us/step - loss: 0.7561 - accuracy: 0.4717\n",
    "[4, 8, 'relu', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 757us/step - loss: 2.8987 - accuracy: 0.5810\n",
    "[4, 8, 'sigmoid', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 1ms/step - loss: 0.8121 - accuracy: 0.4827\n",
    "[4, 8, 'sigmoid', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 773us/step - loss: 0.6850 - accuracy: 0.5332\n",
    "[4, 8, 'sigmoid', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 990us/step - loss: 7.7995 - accuracy: 0.4668\n",
    "[4, 8, 'sigmoid', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 935us/step - loss: 0.7301 - accuracy: 0.5346\n",
    "[4, 8, 'sigmoid', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 775us/step - loss: 0.6953 - accuracy: 0.4760\n",
    "[4, 8, 'sigmoid', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 780us/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[4, 8, 'sigmoid', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 780us/step - loss: 0.7860 - accuracy: 0.4690\n",
    "[4, 8, 'sigmoid', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 840us/step - loss: 0.7141 - accuracy: 0.4694\n",
    "[4, 8, 'sigmoid', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 806us/step - loss: 0.7914 - accuracy: 0.4792\n",
    "[4, 8, 'tanh', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 827us/step - loss: 3.0735 - accuracy: 0.4231\n",
    "[4, 8, 'tanh', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 697us/step - loss: 0.7002 - accuracy: 0.4592\n",
    "[4, 8, 'tanh', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 724us/step - loss: 8.2229 - accuracy: 0.4668\n",
    "[4, 8, 'tanh', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 775us/step - loss: 1.1595 - accuracy: 0.4627\n",
    "[4, 8, 'tanh', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 737us/step - loss: 0.6919 - accuracy: 0.5094\n",
    "[4, 8, 'tanh', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 697us/step - loss: 0.7960 - accuracy: 0.4665\n",
    "[4, 8, 'tanh', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 675us/step - loss: 4.8417 - accuracy: 0.4803\n",
    "[4, 8, 'tanh', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 783us/step - loss: 0.7067 - accuracy: 0.3867\n",
    "[4, 8, 'tanh', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 747us/step - loss: 3.5183 - accuracy: 0.5054\n",
    "[6, 4, 'relu', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 716us/step - loss: 4.5625 - accuracy: 0.4931\n",
    "[6, 4, 'relu', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 689us/step - loss: 0.7082 - accuracy: 0.4377\n",
    "[6, 4, 'relu', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 768us/step - loss: 6.7971 - accuracy: 0.4759\n",
    "[6, 4, 'relu', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 706us/step - loss: 1.8784 - accuracy: 0.4671\n",
    "[6, 4, 'relu', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 719us/step - loss: 0.7081 - accuracy: 0.5319\n",
    "[6, 4, 'relu', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 710us/step - loss: 0.7558 - accuracy: 0.4841\n",
    "[6, 4, 'relu', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 728us/step - loss: 6.1297 - accuracy: 0.4518\n",
    "[6, 4, 'relu', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 714us/step - loss: 0.7071 - accuracy: 0.5332\n",
    "[6, 4, 'relu', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 791us/step - loss: 3.8764 - accuracy: 0.4692\n",
    "[6, 4, 'sigmoid', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 697us/step - loss: 1.7861 - accuracy: 0.5015\n",
    "[6, 4, 'sigmoid', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 712us/step - loss: 0.6855 - accuracy: 0.5332\n",
    "[6, 4, 'sigmoid', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 701us/step - loss: 1.9110 - accuracy: 0.4668\n",
    "[6, 4, 'sigmoid', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 719us/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[6, 4, 'sigmoid', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 734us/step - loss: 0.6912 - accuracy: 0.5349\n",
    "[6, 4, 'sigmoid', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 723us/step - loss: 0.6903 - accuracy: 0.5495\n",
    "[6, 4, 'sigmoid', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 668us/step - loss: 0.6803 - accuracy: 0.5452\n",
    "[6, 4, 'sigmoid', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 741us/step - loss: 0.6963 - accuracy: 0.5060\n",
    "[6, 4, 'sigmoid', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 729us/step - loss: 0.7203 - accuracy: 0.5132\n",
    "[6, 4, 'tanh', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 696us/step - loss: 1.3797 - accuracy: 0.5176\n",
    "[6, 4, 'tanh', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 729us/step - loss: 0.7094 - accuracy: 0.4478\n",
    "[6, 4, 'tanh', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 757us/step - loss: 5.0386 - accuracy: 0.5706\n",
    "[6, 4, 'tanh', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 728us/step - loss: 2.2495 - accuracy: 0.4668\n",
    "[6, 4, 'tanh', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 718us/step - loss: 0.6931 - accuracy: 0.5332\n",
    "[6, 4, 'tanh', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 701us/step - loss: 8.1925 - accuracy: 0.4668\n",
    "[6, 4, 'tanh', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 741us/step - loss: 4.1698 - accuracy: 0.4016\n",
    "[6, 4, 'tanh', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 766us/step - loss: 0.7742 - accuracy: 0.5062\n",
    "[6, 4, 'tanh', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 719us/step - loss: 3.1352 - accuracy: 0.5212\n",
    "[6, 6, 'relu', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 689us/step - loss: 4.7939 - accuracy: 0.4662\n",
    "[6, 6, 'relu', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 718us/step - loss: 0.7712 - accuracy: 0.5134\n",
    "[6, 6, 'relu', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 729us/step - loss: 3.0519 - accuracy: 0.5448\n",
    "[6, 6, 'relu', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 721us/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[6, 6, 'relu', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 759us/step - loss: 0.7379 - accuracy: 0.4778\n",
    "[6, 6, 'relu', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 711us/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[6, 6, 'relu', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 712us/step - loss: 2.9205 - accuracy: 0.4723\n",
    "[6, 6, 'relu', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 737us/step - loss: 0.7118 - accuracy: 0.5731\n",
    "[6, 6, 'relu', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 697us/step - loss: 4.3674 - accuracy: 0.4653\n",
    "[6, 6, 'sigmoid', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 725us/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[6, 6, 'sigmoid', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 752us/step - loss: 0.6839 - accuracy: 0.5092\n",
    "[6, 6, 'sigmoid', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 719us/step - loss: 7.5131 - accuracy: 0.4666\n",
    "[6, 6, 'sigmoid', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 704us/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[6, 6, 'sigmoid', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 717us/step - loss: 0.6914 - accuracy: 0.5194\n",
    "[6, 6, 'sigmoid', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 698us/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[6, 6, 'sigmoid', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 709us/step - loss: 6.4638 - accuracy: 0.4668\n",
    "[6, 6, 'sigmoid', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 713us/step - loss: 0.7178 - accuracy: 0.5332\n",
    "[6, 6, 'sigmoid', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 737us/step - loss: 8.0524 - accuracy: 0.4668\n",
    "[6, 6, 'tanh', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 727us/step - loss: 5.5518 - accuracy: 0.4836\n",
    "[6, 6, 'tanh', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 709us/step - loss: 0.6996 - accuracy: 0.5072\n",
    "[6, 6, 'tanh', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 734us/step - loss: 4.4601 - accuracy: 0.4717\n",
    "[6, 6, 'tanh', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 711us/step - loss: 3.2939 - accuracy: 0.5310\n",
    "[6, 6, 'tanh', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 715us/step - loss: 0.7109 - accuracy: 0.5342\n",
    "[6, 6, 'tanh', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 692us/step - loss: 0.7521 - accuracy: 0.4209\n",
    "[6, 6, 'tanh', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 743us/step - loss: 4.8588 - accuracy: 0.5727\n",
    "[6, 6, 'tanh', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 724us/step - loss: 0.6848 - accuracy: 0.5453\n",
    "[6, 6, 'tanh', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 779us/step - loss: 3.9474 - accuracy: 0.4844\n",
    "[6, 8, 'relu', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 798us/step - loss: 7.4358 - accuracy: 0.4658\n",
    "[6, 8, 'relu', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 805us/step - loss: 0.7224 - accuracy: 0.4883\n",
    "[6, 8, 'relu', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 835us/step - loss: 4.2263 - accuracy: 0.3817\n",
    "[6, 8, 'relu', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 859us/step - loss: 8.0642 - accuracy: 0.4667\n",
    "[6, 8, 'relu', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 827us/step - loss: 0.7551 - accuracy: 0.4639\n",
    "[6, 8, 'relu', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 831us/step - loss: 0.8967 - accuracy: 0.5320\n",
    "[6, 8, 'relu', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 828us/step - loss: 8.4178 - accuracy: 0.4124\n",
    "[6, 8, 'relu', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 737us/step - loss: 0.7595 - accuracy: 0.4891\n",
    "[6, 8, 'relu', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 800us/step - loss: 2.4064 - accuracy: 0.4753\n",
    "[6, 8, 'sigmoid', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 802us/step - loss: 8.1848 - accuracy: 0.4668\n",
    "[6, 8, 'sigmoid', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 833us/step - loss: 0.6904 - accuracy: 0.5345\n",
    "[6, 8, 'sigmoid', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 764us/step - loss: 4.1630 - accuracy: 0.4666\n",
    "[6, 8, 'sigmoid', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 732us/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[6, 8, 'sigmoid', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 764us/step - loss: 0.6885 - accuracy: 0.5700\n",
    "[6, 8, 'sigmoid', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 758us/step - loss: 0.6957 - accuracy: 0.5640\n",
    "[6, 8, 'sigmoid', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 767us/step - loss: 8.0332 - accuracy: 0.4668\n",
    "[6, 8, 'sigmoid', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 740us/step - loss: 0.7250 - accuracy: 0.4675\n",
    "[6, 8, 'sigmoid', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 706us/step - loss: 8.1911 - accuracy: 0.4668\n",
    "[6, 8, 'tanh', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 743us/step - loss: 2.8168 - accuracy: 0.4984\n",
    "[6, 8, 'tanh', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 764us/step - loss: 0.6777 - accuracy: 0.5661\n",
    "[6, 8, 'tanh', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 785us/step - loss: 1.4068 - accuracy: 0.4582\n",
    "[6, 8, 'tanh', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 772us/step - loss: 3.8240 - accuracy: 0.4666\n",
    "[6, 8, 'tanh', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 750us/step - loss: 0.7459 - accuracy: 0.5332\n",
    "[6, 8, 'tanh', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 709us/step - loss: 0.7871 - accuracy: 0.5165\n",
    "[6, 8, 'tanh', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 755us/step - loss: 5.1371 - accuracy: 0.5001\n",
    "[6, 8, 'tanh', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 762us/step - loss: 0.6883 - accuracy: 0.5360\n",
    "[6, 8, 'tanh', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 805us/step - loss: 5.9375 - accuracy: 0.4596\n",
    "[8, 4, 'relu', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 735us/step - loss: 5.8440 - accuracy: 0.4631\n",
    "[8, 4, 'relu', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 785us/step - loss: 0.8931 - accuracy: 0.7118\n",
    "[8, 4, 'relu', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 781us/step - loss: 5.9058 - accuracy: 0.4671\n",
    "[8, 4, 'relu', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 770us/step - loss: 1.5792 - accuracy: 0.4316\n",
    "[8, 4, 'relu', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 753us/step - loss: 0.7142 - accuracy: 0.5332\n",
    "[8, 4, 'relu', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 743us/step - loss: 8.1923 - accuracy: 0.4671\n",
    "[8, 4, 'relu', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 748us/step - loss: 8.2228 - accuracy: 0.4668\n",
    "[8, 4, 'relu', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 697us/step - loss: 0.7339 - accuracy: 0.4471\n",
    "[8, 4, 'relu', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 688us/step - loss: 1.4815 - accuracy: 0.4447\n",
    "[8, 4, 'sigmoid', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 761us/step - loss: 0.9480 - accuracy: 0.4272\n",
    "[8, 4, 'sigmoid', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 687us/step - loss: 0.6906 - accuracy: 0.5332\n",
    "[8, 4, 'sigmoid', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 747us/step - loss: 3.8862 - accuracy: 0.4675\n",
    "[8, 4, 'sigmoid', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 749us/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[8, 4, 'sigmoid', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 743us/step - loss: 0.6966 - accuracy: 0.5332\n",
    "[8, 4, 'sigmoid', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 775us/step - loss: 1.6800 - accuracy: 0.4661\n",
    "[8, 4, 'sigmoid', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 754us/step - loss: 5.6485 - accuracy: 0.5329\n",
    "[8, 4, 'sigmoid', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 790us/step - loss: 0.7005 - accuracy: 0.5342\n",
    "[8, 4, 'sigmoid', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 800us/step - loss: 0.6923 - accuracy: 0.4812\n",
    "[8, 4, 'tanh', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 781us/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[8, 4, 'tanh', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 719us/step - loss: 0.7601 - accuracy: 0.4514\n",
    "[8, 4, 'tanh', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 704us/step - loss: 5.8894 - accuracy: 0.4668\n",
    "[8, 4, 'tanh', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 729us/step - loss: 8.1891 - accuracy: 0.4668\n",
    "[8, 4, 'tanh', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 734us/step - loss: 0.7046 - accuracy: 0.5219\n",
    "[8, 4, 'tanh', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 724us/step - loss: 0.7082 - accuracy: 0.5255\n",
    "[8, 4, 'tanh', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 768us/step - loss: 3.1226 - accuracy: 0.4721\n",
    "[8, 4, 'tanh', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 723us/step - loss: 0.7242 - accuracy: 0.3502\n",
    "[8, 4, 'tanh', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 747us/step - loss: 3.2006 - accuracy: 0.5240\n",
    "[8, 6, 'relu', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 761us/step - loss: 3.6855 - accuracy: 0.5283\n",
    "[8, 6, 'relu', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 804us/step - loss: 1.4479 - accuracy: 0.7072\n",
    "[8, 6, 'relu', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 755us/step - loss: 0.9271 - accuracy: 0.6226\n",
    "[8, 6, 'relu', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 1ms/step - loss: 5.4799 - accuracy: 0.5299\n",
    "[8, 6, 'relu', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 969us/step - loss: 0.7184 - accuracy: 0.5322\n",
    "[8, 6, 'relu', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 1ms/step - loss: 4.5519 - accuracy: 0.4669\n",
    "[8, 6, 'relu', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 1ms/step - loss: 5.6087 - accuracy: 0.4633\n",
    "[8, 6, 'relu', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 937us/step - loss: 0.6667 - accuracy: 0.6613\n",
    "[8, 6, 'relu', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 980us/step - loss: 5.1719 - accuracy: 0.4097\n",
    "[8, 6, 'sigmoid', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 1ms/step - loss: 1.6027 - accuracy: 0.4938\n",
    "[8, 6, 'sigmoid', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5100\n",
    "[8, 6, 'sigmoid', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 943us/step - loss: 7.7384 - accuracy: 0.4668\n",
    "[8, 6, 'sigmoid', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 1ms/step - loss: 8.2229 - accuracy: 0.4668\n",
    "[8, 6, 'sigmoid', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 915us/step - loss: 0.6947 - accuracy: 0.4753\n",
    "[8, 6, 'sigmoid', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 899us/step - loss: 6.8022 - accuracy: 0.4668\n",
    "[8, 6, 'sigmoid', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 896us/step - loss: 8.1959 - accuracy: 0.4668\n",
    "[8, 6, 'sigmoid', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5356\n",
    "[8, 6, 'sigmoid', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 884us/step - loss: 6.4357 - accuracy: 0.4844\n",
    "[8, 6, 'tanh', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 855us/step - loss: 6.7551 - accuracy: 0.4658\n",
    "[8, 6, 'tanh', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 844us/step - loss: 0.6966 - accuracy: 0.4299\n",
    "[8, 6, 'tanh', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 872us/step - loss: 1.5161 - accuracy: 0.4115\n",
    "[8, 6, 'tanh', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 1ms/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[8, 6, 'tanh', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 1ms/step - loss: 0.7571 - accuracy: 0.5332\n",
    "[8, 6, 'tanh', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 880us/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[8, 6, 'tanh', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 891us/step - loss: 4.9398 - accuracy: 0.4599\n",
    "[8, 6, 'tanh', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 832us/step - loss: 0.6817 - accuracy: 0.5348\n",
    "[8, 6, 'tanh', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 1ms/step - loss: 3.7445 - accuracy: 0.4903\n",
    "[8, 8, 'relu', 'relu', 'relu']\n",
    "268/268 [==============================] - 0s 709us/step - loss: 7.1213 - accuracy: 0.4680\n",
    "[8, 8, 'relu', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.5422\n",
    "[8, 8, 'relu', 'relu', 'tanh']\n",
    "268/268 [==============================] - 0s 822us/step - loss: 5.9312 - accuracy: 0.4639\n",
    "[8, 8, 'relu', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 0s 1ms/step - loss: 1.6375 - accuracy: 0.4716\n",
    "[8, 8, 'relu', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 0s 933us/step - loss: 0.6878 - accuracy: 0.5790\n",
    "[8, 8, 'relu', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 0s 1ms/step - loss: 1.3314 - accuracy: 0.4883\n",
    "[8, 8, 'relu', 'tanh', 'relu']\n",
    "268/268 [==============================] - 0s 1ms/step - loss: 4.4232 - accuracy: 0.5062\n",
    "[8, 8, 'relu', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 0s 1ms/step - loss: 0.8396 - accuracy: 0.4767\n",
    "[8, 8, 'relu', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 0s 991us/step - loss: 3.1963 - accuracy: 0.4387\n",
    "[8, 8, 'sigmoid', 'relu', 'relu']\n",
    "268/268 [==============================] - 1s 2ms/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[8, 8, 'sigmoid', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 1s 2ms/step - loss: 0.7259 - accuracy: 0.4570\n",
    "[8, 8, 'sigmoid', 'relu', 'tanh']\n",
    "268/268 [==============================] - 1s 2ms/step - loss: 0.9224 - accuracy: 0.4619\n",
    "[8, 8, 'sigmoid', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 1s 2ms/step - loss: 8.2242 - accuracy: 0.4668\n",
    "[8, 8, 'sigmoid', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5327\n",
    "[8, 8, 'sigmoid', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 1s 2ms/step - loss: 2.9953 - accuracy: 0.4668\n",
    "[8, 8, 'sigmoid', 'tanh', 'relu']\n",
    "268/268 [==============================] - 1s 2ms/step - loss: 0.8345 - accuracy: 0.4627\n",
    "[8, 8, 'sigmoid', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 1s 2ms/step - loss: 0.6966 - accuracy: 0.5257\n",
    "[8, 8, 'sigmoid', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 1s 2ms/step - loss: 7.5245 - accuracy: 0.4669\n",
    "[8, 8, 'tanh', 'relu', 'relu']\n",
    "268/268 [==============================] - 1s 2ms/step - loss: 7.5079 - accuracy: 0.4702\n",
    "[8, 8, 'tanh', 'relu', 'sigmoid']\n",
    "268/268 [==============================] - 1s 2ms/step - loss: 0.6888 - accuracy: 0.5956\n",
    "[8, 8, 'tanh', 'relu', 'tanh']\n",
    "268/268 [==============================] - 1s 2ms/step - loss: 7.0334 - accuracy: 0.4666\n",
    "[8, 8, 'tanh', 'sigmoid', 'relu']\n",
    "268/268 [==============================] - 1s 4ms/step - loss: 2.2514 - accuracy: 0.5535\n",
    "[8, 8, 'tanh', 'sigmoid', 'sigmoid']\n",
    "268/268 [==============================] - 1s 2ms/step - loss: 0.6982 - accuracy: 0.4679\n",
    "[8, 8, 'tanh', 'sigmoid', 'tanh']\n",
    "268/268 [==============================] - 1s 2ms/step - loss: 0.7035 - accuracy: 0.5301\n",
    "[8, 8, 'tanh', 'tanh', 'relu']\n",
    "268/268 [==============================] - 1s 2ms/step - loss: 3.7115 - accuracy: 0.4707\n",
    "[8, 8, 'tanh', 'tanh', 'sigmoid']\n",
    "268/268 [==============================] - 1s 2ms/step - loss: 0.7517 - accuracy: 0.4000\n",
    "[8, 8, 'tanh', 'tanh', 'tanh']\n",
    "268/268 [==============================] - 1s 2ms/step - loss: 4.2154 - accuracy: 0.4780"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance.sort_values(by=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
